# scripts/train_outetts.py
import os
import torch
from datasets import load_dataset, Audio
from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM, TrainingArguments
from peft import LoraConfig, get_peft_model, PeftModel
from trl import SFTTrainer
from outetts import Interface, GenerationConfig, Backend, GenerationType, SamplerConfig
import outetts

# è¨­å®šæœ¬åœ°æ¨¡å‹è·¯å¾‘
base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
model_dir = os.path.join(base_dir, "models", "Llama-OuteTTS-1.0-1B")

# ========== çºŒæ¥è¨“ç·´è¨­å®š ==========
CONTINUE_TRAINING = False  # è¨­ç‚º True ä¾†çºŒæ¥ä¹‹å‰çš„è¨“ç·´
ADAPTER_PATH = os.path.join(base_dir, "outputs", "lora_model")  # ä¹‹å‰è¨“ç·´çš„adapterè·¯å¾‘
NEW_OUTPUT_DIR = os.path.join(base_dir, "outputs", "lora_model_v2")  # æ–°çš„è¼¸å‡ºç›®éŒ„

print(f"Loading model from local path: {model_dir}")
if CONTINUE_TRAINING and os.path.exists(ADAPTER_PATH):
    print(f"Continuing training from adapter: {ADAPTER_PATH}")
else:
    print("Starting fresh training")

# 1. è¼‰å…¥å’Œè™•ç† dataset
print("Loading and processing dataset...")

# å…ˆå‰µå»ºæ­£ç¢ºæ ¼å¼çš„æ•¸æ“šé›†
import json

# è®€å–åŸå§‹JSONæ•¸çµ„
with open(os.path.join(base_dir, "data", "dataset.json"), "r", encoding="utf-8-sig") as f:
    original_data = json.load(f)

# è½‰æ›ç‚ºæ­£ç¢ºæ ¼å¼ä¸¦ä¿®æ­£è·¯å¾‘
processed_data = []
for item in original_data:
    # ä¿®æ­£éŸ³é »è·¯å¾‘
    audio_path = item["audio"].replace("...", base_dir.replace("\\", "/"))
    audio_path = os.path.normpath(audio_path)
    
    processed_item = {
        "audio": audio_path,
        "text": item["transcript"]  # æ”¹ç‚º 'text' æ¬„ä½ï¼Œæ›´ç¬¦åˆæ¨™æº–
    }
    processed_data.append(processed_item)

# å‰µå»ºè‡¨æ™‚çš„JSONLæ ¼å¼æ–‡ä»¶
temp_dataset_path = os.path.join(base_dir, "data", "temp_dataset.jsonl")
with open(temp_dataset_path, "w", encoding="utf-8") as f:
    for item in processed_data:
        f.write(json.dumps(item, ensure_ascii=False) + "\n")

print(f"Processed {len(processed_data)} samples")

# è¼‰å…¥è™•ç†å¾Œçš„æ•¸æ“šé›†
ds = load_dataset("json", data_files=temp_dataset_path, split="train")
ds = ds.cast_column("audio", Audio(sampling_rate=24000))

# 2. å¾æœ¬åœ°è¼‰å…¥ Tokenizer & Base Model èˆ‡é‡åŒ–è¨­ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
    bnb_4bit_compute_dtype=torch.float16  # ä½¿ç”¨ torch.float16 è€Œä¸æ˜¯å­—ä¸²
)

# å¾æœ¬åœ°è¼‰å…¥
tokenizer = AutoTokenizer.from_pretrained(
    model_dir, 
    trust_remote_code=True,
    local_files_only=True  # ç¢ºä¿åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
)
model = AutoModelForCausalLM.from_pretrained(
    model_dir,
    quantization_config=bnb_config,
    device_map="auto",
    trust_remote_code=True,
    local_files_only=True,  # ç¢ºä¿åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
    torch_dtype=torch.float16
)

# ç¢ºä¿æ¨¡å‹æœ‰ pad_token
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# 3. LoRA Adapter è¨­å®šå’Œè¼‰å…¥
if CONTINUE_TRAINING and os.path.exists(ADAPTER_PATH):
    print("Loading existing adapter for continued training...")
    # è¼‰å…¥å·²è¨“ç·´çš„adapter
    model = PeftModel.from_pretrained(model, ADAPTER_PATH)
    # ç²å–ç•¶å‰çš„LoRAé…ç½®
    lora_config = model.peft_config['default']
    print(f"Loaded adapter with r={lora_config.r}, alpha={lora_config.lora_alpha}")
else:
    print("Creating new LoRA adapter...")
    # å‰µå»ºæ–°çš„LoRAé…ç½®
    lora_config = LoraConfig(
        r=32, # å¢åŠ  r å€¼æå‡æ•ˆæœ
        lora_alpha=32,  # å¢åŠ  alpha å€¼æå‡æ•ˆæœ
        target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],  # å¢åŠ æ›´å¤šç›®æ¨™æ¨¡çµ„
        lora_dropout=0.1,
        bias="none",
        task_type="CAUSAL_LM"
    )
    model = get_peft_model(model, lora_config)

# 4. è¨“ç·´åƒæ•¸è¨­å®š - ä½¿ç”¨ TrainingArguments
training_args = TrainingArguments(
    output_dir=os.path.join(base_dir, "outputs", "lora_model"),  # ä½¿ç”¨çµ•å°è·¯å¾‘
    learning_rate=5e-6,
    per_device_train_batch_size=1,
    gradient_accumulation_steps=4,  # å¢åŠ æœ‰æ•ˆ batch size
    num_train_epochs=10,
    save_steps=500,
    logging_steps=100,
    warmup_steps=100,
    dataloader_num_workers=0,  # Windows å»ºè­°è¨­ç‚º 0
    fp16=True,  # å•Ÿç”¨æ··åˆç²¾åº¦
    report_to=None,  # é—œé–‰ wandb ç­‰å ±å‘Š
    save_total_limit=2,  # åªä¿ç•™æœ€æ–°çš„ 2 å€‹ checkpoint
    remove_unused_columns=False,  # ä¿ç•™éŸ³é »æ¬„ä½
    max_steps=-1,  # ä½¿ç”¨ epochs è€Œä¸æ˜¯ steps
)

# æ•¸æ“šé è™•ç† - ç‚ºSFTTraineræº–å‚™æ–‡æœ¬æ ¼å¼
def format_dataset(examples):
    """å°‡æ•¸æ“šæ ¼å¼åŒ–ç‚ºSFTTraineræœŸæœ›çš„æ ¼å¼"""
    texts = examples['text']
    # ç‚ºOuteTTSæ ¼å¼åŒ–æ–‡æœ¬
    formatted_texts = []
    for text in texts:
        # ç°¡å–®çš„æ ¼å¼åŒ–ï¼Œå¯¦éš›å¯èƒ½éœ€è¦æ›´è¤‡é›œçš„è™•ç†
        formatted_text = f"<|text|>{text}<|audio|>"
        formatted_texts.append(formatted_text)
    
    return {"text": formatted_texts}

# æ ¼å¼åŒ–æ•¸æ“šé›†
print("Formatting dataset for training...")
formatted_ds = ds.map(
    format_dataset, 
    batched=True, 
    remove_columns=[col for col in ds.column_names if col != 'text'],  # åªä¿ç•™audioå’Œè™•ç†å¾Œçš„text
    desc="Formatting"
)

# 5. å»ºç«‹ Trainer ä¸¦è¨“ç·´
trainer = SFTTrainer(
    model=model,
    train_dataset=formatted_ds,  # ä½¿ç”¨æ ¼å¼åŒ–çš„æ•¸æ“šé›†
    args=training_args,
    processing_class=tokenizer,  # ä½¿ç”¨ processing_class è€Œä¸æ˜¯ tokenizer
    peft_config=lora_config,  # æ·»åŠ  peft_config
)

print("Starting training...")
trainer.train()

# å„²å­˜æ¨¡å‹
print("Saving model...")
output_path = os.path.join(base_dir, "outputs", "lora_model")
os.makedirs(output_path, exist_ok=True)

try:
    # ä½¿ç”¨trainerçš„save_modelæ–¹æ³•
    trainer.save_model(output_path)
    print(f"âœ… Trainer model saved to: {output_path}")
except Exception as e:
    print(f"âŒ Trainer save failed: {e}")

try:
    # å–®ç¨ä¿å­˜adapteræ¬Šé‡
    if hasattr(model, 'save_pretrained'):
        model.save_pretrained(output_path)
        print(f"âœ… PEFT adapter saved to: {output_path}")
except Exception as e:
    print(f"âŒ PEFT save failed: {e}")

try:
    # ä¿å­˜tokenizer
    tokenizer.save_pretrained(output_path)
    print(f"âœ… Tokenizer saved to: {output_path}")
except Exception as e:
    print(f"âŒ Tokenizer save failed: {e}")

# æª¢æŸ¥ä¿å­˜çš„æ–‡ä»¶
saved_files = [f for f in os.listdir(output_path) if f.endswith(('.bin', '.safetensors', '.json'))]
print(f"ğŸ“ Saved files: {saved_files}")

print(f"Training completed! Check: {output_path}")

# 6. æ¸¬è©¦ç”Ÿæˆï¼ˆå¯é¸ï¼‰
try:
    print("Testing generation with trained adapter...")
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs("../outputs/samples", exist_ok=True)
    
    # ä½¿ç”¨æœ¬åœ°æ¨¡å‹å’Œè¨“ç·´å¥½çš„ adapter
    interface = Interface(
        config=outetts.ModelConfig(
            model_path=model_dir,
            tokenizer_path=model_dir,
            interface_version=outetts.InterfaceVersion.V3,
            backend=outetts.Backend.HF,
            # adapter_path="outputs/lora_model"  # å¦‚æœ OuteTTS æ”¯æ´ adapter è¼‰å…¥
        )
    )
    
    # è¼‰å…¥èªªè©±è€…
    if os.path.exists("../speaker/uep_speaker.json"):
        speaker = interface.load_speaker("../speaker/uep_speaker.json")
    else:
        # ä½¿ç”¨é è¨­èªªè©±è€…
        speaker = interface.load_default_speaker("EN-FEMALE-1-NEUTRAL")
    
    # ç”Ÿæˆæ¸¬è©¦èªéŸ³
    output = interface.generate(
        config=GenerationConfig(
        text="Oh my gosh, stories are just the best! They whisk you away to different worlds and introduce you to amazing characters. The emotions, the adventures... I just love getting lost in them!",
        generation_type=GenerationType.CHUNKED,
        speaker=speaker,
        sampler_config=SamplerConfig(
            temperature=0.4,
            repetition_penalty=1.1,
            # é‡è¦ Sampling è¨­å®šï¼ŒOuteTTSâ€‘1.0 è¦é™åˆ¶åœ¨ 64-token recent window æ‰èƒ½é¿å…ç ´éŸ³ :contentReference[oaicite:1]{index=1}
            repetition_range=64,
            top_k=40,
            top_p=0.9,
            min_p=0.05
        ),
    )
    )
    
    output.save("../outputs/samples/test.wav")
    print("Sample output saved to outputs/samples/test.wav")
    
except Exception as e:
    print(f"Generation test failed: {e}")
    print("Training completed successfully, but generation test skipped.")
